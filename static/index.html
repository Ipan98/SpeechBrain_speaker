<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="theme-color" content="#000000" />
  <meta name="description" content="Emotion Recognition App - Record your voice and discover the emotion" />
  <title>Emotion Recognition</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
  <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
</head>
<body>
  <noscript>You need to enable JavaScript to run this app.</noscript>
  <div id="root"></div>
  
  <script type="text/babel">
    const { useState, useRef, useEffect } = React;

    const API_URL = window.location.origin;

    function App() {
      const [isRecording, setIsRecording] = useState(false);
      const [audioURL, setAudioURL] = useState('');
      const [result, setResult] = useState(null);
      const [loading, setLoading] = useState(false);
      const [error, setError] = useState('');
      
      const mediaRecorderRef = useRef(null);
      const audioChunksRef = useRef([]);

      useEffect(() => {
        // Request microphone permission on mount
        navigator.mediaDevices.getUserMedia({ audio: true })
          .catch(err => setError('Microphone access denied. Please allow microphone access.'));
      }, []);

      const startRecording = async () => {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          const mediaRecorder = new MediaRecorder(stream);
          mediaRecorderRef.current = mediaRecorder;
          audioChunksRef.current = [];

          mediaRecorder.ondataavailable = (event) => {
            audioChunksRef.current.push(event.data);
          };

          mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
            const url = URL.createObjectURL(audioBlob);
            setAudioURL(url);
            
            // Stop all tracks
            stream.getTracks().forEach(track => track.stop());
          };

          mediaRecorder.start();
          setIsRecording(true);
          setError('');
          setResult(null);
        } catch (err) {
          setError('Failed to start recording: ' + err.message);
        }
      };

      const stopRecording = () => {
        if (mediaRecorderRef.current && isRecording) {
          mediaRecorderRef.current.stop();
          setIsRecording(false);
        }
      };

      const classifyAudio = async () => {
        if (!audioChunksRef.current.length) {
          setError('No audio recorded');
          return;
        }

        setLoading(true);
        setError('');
        setResult(null);

        try {
          const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
          const formData = new FormData();
          formData.append('audio', audioBlob, 'recording.wav');

          const response = await fetch(`${API_URL}/api/classify`, {
            method: 'POST',
            body: formData,
          });

          if (!response.ok) {
            const errorData = await response.json();
            throw new Error(errorData.error || 'Classification failed');
          }

          const data = await response.json();
          setResult(data);
        } catch (err) {
          setError('Classification error: ' + err.message);
        } finally {
          setLoading(false);
        }
      };

      const reset = () => {
        setAudioURL('');
        setResult(null);
        setError('');
        audioChunksRef.current = [];
      };

      const getEmotionColor = (emotion) => {
        const colors = {
          'hap': 'bg-yellow-100 text-yellow-800 border-yellow-300',
          'sad': 'bg-blue-100 text-blue-800 border-blue-300',
          'ang': 'bg-red-100 text-red-800 border-red-300',
          'neu': 'bg-gray-100 text-gray-800 border-gray-300',
          'fea': 'bg-purple-100 text-purple-800 border-purple-300',
        };
        return colors[emotion] || 'bg-green-100 text-green-800 border-green-300';
      };

      const getEmotionLabel = (emotion) => {
        const labels = {
          'hap': 'Happy',
          'sad': 'Sad',
          'ang': 'Angry',
          'neu': 'Neutral',
          'fea': 'Fearful',
        };
        return labels[emotion] || emotion;
      };

      return (
        <div className="min-h-screen bg-gradient-to-br from-indigo-100 via-purple-50 to-pink-100 py-12 px-4">
          <div className="max-w-2xl mx-auto">
            <div className="bg-white rounded-2xl shadow-xl p-8">
              <h1 className="text-4xl font-bold text-center mb-2 bg-gradient-to-r from-indigo-600 to-purple-600 bg-clip-text text-transparent">
                Emotion Recognition
              </h1>
              <p className="text-center text-gray-600 mb-8">
                Record your voice and discover the emotion
              </p>

              <div className="space-y-6">
                {/* Recording Controls */}
                <div className="flex justify-center gap-4">
                  {!isRecording ? (
                    <button
                      onClick={startRecording}
                      className="px-8 py-3 bg-gradient-to-r from-indigo-600 to-purple-600 text-white rounded-lg font-semibold hover:from-indigo-700 hover:to-purple-700 transition-all shadow-lg hover:shadow-xl"
                    >
                      üé§ Start Recording
                    </button>
                  ) : (
                    <button
                      onClick={stopRecording}
                      className="px-8 py-3 bg-red-600 text-white rounded-lg font-semibold hover:bg-red-700 transition-all shadow-lg hover:shadow-xl animate-pulse"
                    >
                      ‚èπ Stop Recording
                    </button>
                  )}
                </div>

                {/* Recording Indicator */}
                {isRecording && (
                  <div className="text-center">
                    <div className="inline-flex items-center gap-2 px-4 py-2 bg-red-50 border border-red-200 rounded-lg">
                      <div className="w-3 h-3 bg-red-600 rounded-full animate-pulse"></div>
                      <span className="text-red-800 font-medium">Recording...</span>
                    </div>
                  </div>
                )}

                {/* Audio Player */}
                {audioURL && (
                  <div className="bg-gray-50 rounded-lg p-6 space-y-4">
                    <h3 className="font-semibold text-gray-700">Your Recording:</h3>
                    <audio src={audioURL} controls className="w-full" />
                    
                    <div className="flex gap-3 justify-center">
                      <button
                        onClick={classifyAudio}
                        disabled={loading}
                        className="px-6 py-2 bg-indigo-600 text-white rounded-lg font-semibold hover:bg-indigo-700 transition-all disabled:opacity-50 disabled:cursor-not-allowed"
                      >
                        {loading ? 'Analyzing...' : 'üîç Classify Emotion'}
                      </button>
                      
                      <button
                        onClick={reset}
                        className="px-6 py-2 bg-gray-600 text-white rounded-lg font-semibold hover:bg-gray-700 transition-all"
                      >
                        üîÑ New Recording
                      </button>
                    </div>
                  </div>
                )}

                {/* Loading State */}
                {loading && (
                  <div className="text-center py-8">
                    <div className="inline-block w-12 h-12 border-4 border-indigo-600 border-t-transparent rounded-full animate-spin"></div>
                    <p className="mt-4 text-gray-600">Analyzing emotion...</p>
                  </div>
                )}

                {/* Results */}
                {result && !loading && (
                  <div className={`border-2 rounded-lg p-6 ${getEmotionColor(result.emotion)}`}>
                    <h3 className="text-lg font-semibold mb-2">Detected Emotion:</h3>
                    <div className="text-3xl font-bold mb-2">
                      {getEmotionLabel(result.emotion)}
                    </div>
                    <div className="text-sm">
                      Confidence: {(result.confidence * 100).toFixed(1)}%
                    </div>
                  </div>
                )}

                {/* Error Message */}
                {error && (
                  <div className="bg-red-50 border-2 border-red-200 rounded-lg p-4">
                    <p className="text-red-800">{error}</p>
                  </div>
                )}
              </div>
            </div>

            {/* Instructions */}
            <div className="mt-8 bg-white rounded-lg shadow-md p-6">
              <h3 className="font-semibold text-gray-800 mb-3">How to use:</h3>
              <ol className="list-decimal list-inside space-y-2 text-gray-600">
                <li>Click "Start Recording" and allow microphone access</li>
                <li>Speak naturally for a few seconds</li>
                <li>Click "Stop Recording" when finished</li>
                <li>Click "Classify Emotion" to analyze your voice</li>
                <li>The AI will detect emotions: Happy, Sad, Angry, Neutral, or Fearful</li>
              </ol>
            </div>
          </div>
        </div>
      );
    }

    ReactDOM.render(<App />, document.getElementById('root'));
  </script>
</body>
</html>